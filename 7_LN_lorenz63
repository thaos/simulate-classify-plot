#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Mar  9 15:38:43 2021

@author: vborse
"""

from IPython.display import clear_output, display, HTML

import numpy as np
import pandas as pd
import seaborn as sns
from scipy import integrate
import math
from matplotlib import pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.colors import cnames
from matplotlib import animation
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

from module mport lorenz
from module import single_traj
    
# ------------------MAIN BODY OF THE CODE-----------------------------    
r=28
R=1
pts=single_traj(4,-14,21,r,0.01,10000) 
#with open('pts.npy', 'wb') as h:
#    np.save(h, pts)
#pts=np.load('pts.npy')
X1=np.transpose(pts)


pts2=single_traj(1,-1,2.05,r,0.01,10000)
X2=np.transpose(pts2)

covMatrix = np.corrcoef(X,bias=True)
y=np.dot(covMatrix,X)
Y=np.dot(covMatrix,X)
Y1=np.dot(covMatrix,X)
Y2=np.dot(covMatrix,X)

y_pred=[]
y_pred1=[]
y_pred2=[]
t_steps=50
index=2

#------------UNIVARIATE LINEAR REGRESSION ---------------------------------

def ideal (pt=pts):
    
    print(pt)
    X=np.transpose(pt)
    for i,item in enumerate(X):
        for j,jitem in enumerate(X[i]):
            if ((j+t_steps)<=(len(X[i])-1)):
                Y[i][j]=X[i][j+t_steps]
            else:
                Y[i][j]=0
    return X, Y

def non_recursive_LN (Xt,t_steps,ind,pt=pts):
    
    X_tr, Y_tr = ideal(pt)
    
    model1 = LinearRegression().fit(X_tr[ind].reshape(-1,1), Y_tr[ind])
    r_sq = model1.score(X_tr[ind].reshape(-1,1), Y_tr[ind])
    intercept1, coefficients1 = model1.intercept_, model1.coef_
    
    Ynew=model1.predict(Xt.reshape(-1,1))
    
    return intercept1, coefficients1, Ynew

def recursive_LN (Xt,t_steps,ind,pt=pts):
    
    X_tr, Y_tr = ideal(pt)
    
    model2 = LinearRegression().fit(X_tr[ind].reshape(-1,1), Y_tr[ind])
    r_sq = model2.score(X_tr[ind].reshape(-1,1), Y_tr[ind])
    intercept2, coefficients2 = model2.intercept_, model2.coef_
    
    Xnew=Xt

    for i in range(t_steps):
        if i == 0:
            Xnew =  Xt
        else:
            Ynew = model2.predict(np.array([Xnew]).reshape(-1,1))
            
    return intercept2, coefficients2, Ynew

X1, Y1= ideal(pts)
X2, Y2= ideal(pts2)
i1,c1,y_pred1=non_recursive_LN (X2[index], t_steps,index,pts2)
i2,c2,y_pred2=recursive_LN (X2[index], t_steps,index,pts2)

fig, axs = plt.subplots(2, 2, sharex=False,sharey=False, figsize=(15,5))
fig.suptitle('Univariate Linear Regression; dt=0.01')
axs[0,0].scatter(y_pred1[:-(t_steps+1)],Y2[index][:-(t_steps+1)],s=2)
axs[0,0].plot(Y2[index][:-(t_steps+1)],Y2[index][:-(t_steps+1)],'r')
axs[0,0].set_xlabel("y_pred")
axs[0,0].set_ylabel("y_ideal")
axs[0,0].set_title("Non-recursive LN")
    
axs[0,1].scatter(y_pred2[:-(t_steps+1)],Y2[index][:-(t_steps+1)],s=2)
axs[0,1].plot(Y2[index][:-(t_steps+1)],Y2[index][:-(t_steps+1)],'r')
axs[0,1].set_xlabel("y_pred")
axs[0,1].set_ylabel("y_ideal")
axs[0,1].set_title("Recursive LN")
    
axs[1,0].plot(y_pred1[:-(t_steps+1)]-Y2[index][:-(t_steps+1)],'b')
axs[1,0].plot(y_pred2[:-(t_steps+1)]-Y2[index][:-(t_steps+1)],'r')
axs[1,0].set_ylabel("error")
axs[1,0].set_xlabel("time_steps")
axs[1,0].set_title("Errors for LN")
    
axs[1,1].scatter(X2[index][:-(t_steps+1)],Y2[index][:-(t_steps+1)],s=2)
axs[1,1].scatter(X2[index][:-(t_steps+1)],y_pred1[:-(t_steps+1)],s=2)
axs[1,1].scatter(X2[index][:-(t_steps+1)],y_pred2[:-(t_steps+1)],s=2)
axs[1,1].set_xlabel("X(x,y,z)")
axs[1,1].set_ylabel("Y")

#---------------MULTIVARIATE LINEAR REGRESSION----------------------------------------
def ideal (pt=pts):
    
    print(pt)
    X=np.transpose(pt)
    for i,item in enumerate(X):
        for j,jitem in enumerate(X[i]):
            if ((j+t_steps)<=(len(X[i])-1)):
                Y[i][j]=X[i][j+t_steps]
            else:
                Y[i][j]=0
    return X, Y

def m_non_recursive_LN (Xt,t_steps,ind,pt=pts):
    
    X_tr, Y_tr = ideal(pt)
    
    model1 = LinearRegression().fit(X_tr.T,Y_tr[ind])
    r_sq = model1.score(X_tr.T, Y_tr[ind])
    intercept1, coefficients1 = model1.intercept_, model1.coef_
    
    Ynew=model1.predict(Xt.T)
    
    return intercept1, coefficients1, Ynew

def m_recursive_LN (Xt,t_steps,ind,pt=pts):
    
    X_tr, Y_tr = ideal(pt)
    
    model2 = LinearRegression().fit(X_tr.T, Y_tr[ind])
    r_sq = model2.score(X_tr.T, Y_tr[ind])
    intercept2, coefficients2 = model2.intercept_, model2.coef_
    
    Xnew=Xt

    for i in range(t_steps):
        if i == 0:
            Xnew =  Xt
        else:
            Ynew = model2.predict(Xnew.T)
            
    return intercept2, coefficients2, Ynew

X1, Y1= ideal(pts)
X2, Y2= ideal(pts2)
i1,c1,y_pred1=m_non_recursive_LN (X2, t_steps,index,pts2)
i2,c2,y_pred2=m_recursive_LN (X2, t_steps,index,pts2)

fig, axs = plt.subplots(2, 2, sharex=False,sharey=False, figsize=(15,5))
fig.suptitle('Multivariate Linear Regression; dt=0.01')
axs[0,0].scatter(y_pred1[:-(t_steps+1)],Y2[index][:-(t_steps+1)],s=2)
axs[0,0].plot(Y2[index][:-(t_steps+1)],Y2[index][:-(t_steps+1)],'r')
axs[0,0].set_xlabel("y_pred")
axs[0,0].set_ylabel("y_ideal")
axs[0,0].set_title("Non-recursive LN")
       
axs[0,1].scatter(y_pred2[:-(t_steps+1)],Y2[index][:-(t_steps+1)],s=2)
axs[0,1].plot(Y2[index][:-(t_steps+1)],Y2[index][:-(t_steps+1)],'r')
axs[0,1].set_xlabel("y_pred")
axs[0,1].set_ylabel("y_ideal")
axs[0,1].set_title("Recursive LN")
       
axs[1,0].plot(y_pred1[:-(t_steps+1)]-Y2[index][:-(t_steps+1)],'b')
axs[1,0].plot(y_pred2[:-(t_steps+1)]-Y2[index][:-(t_steps+1)],'r')
axs[1,0].set_ylabel("error")
axs[1,0].set_xlabel("time_steps")
axs[1,0].set_title("Errors for LN")
      
axs[1,1].scatter(X2[index][:-(t_steps+1)],Y2[index][:-(t_steps+1)],s=2)
axs[1,1].scatter(X2[index][:-(t_steps+1)],y_pred1[:-(t_steps+1)],s=2)
axs[1,1].scatter(X2[index][:-(t_steps+1)],y_pred2[:-(t_steps+1)],s=2)
axs[1,1].set_xlabel("X(x,y,z)")
axs[1,1].set_ylabel("Y")
